---
title: Multi-armed bandits problem
slug: bandits
description: null
author: null
date: 2022-05-02T09:25:42.692Z
lastmod: 2022-05-03T06:18:08.232Z
draft: false
tags:
  - bandit algorithms
  - online learning
  - reinforcement learning
  - rl
  - linkage
categories:
  - learning
  - linkage
  - rl
header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
---


# Books

# Posts and Papers
- [An Efficient Bandit Algorithm for Realtime Multivariate
Optimization](https://dl.acm.org/doi/pdf/10.1145/3097983.3098184) Amazon
- [Thompson Sampling for Contextual Bandit Problems
with Auxiliary Safety Constraints](https://scontent.fhfa2-2.fna.fbcdn.net/v/t39.8562-6/240832401_626971034933869_262283130026823854_n.pdf?_nc_cat=106&ccb=1-5&_nc_sid=ad8a9d&_nc_ohc=x0_fBLaoskgAX-fIgRL&_nc_ht=scontent.fhfa2-2.fna&oh=00_AT9aTN5qWE-srrWgSWBDF6ez0kNYM5n2XX4WkLRx_zvX9A&oe=626EEA04) Facebook
- [Multi-Armed Bandits and the Stitch Fix Experimentation Platform](https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/) Stitchfix
- [Using a Multi-Armed Bandit with Thompson Sampling to Identify Responsive Dashers](https://doordash.engineering/2022/03/15/using-a-multi-armed-bandit-with-thompson-sampling-to-identify-responsive-dashers/) DoorDash
- [Multi-Armed Bandit Algorithms: Thompson Sampling](https://towardsdatascience.com/
- [A Multi-Armed Bandit Framework for Recommendations](multi-armed-bandit-algorithms-thompson-sampling-6d91a88145db)
https://info.dataengconf.com/hubfs/SF%2018%20-%20Slides/DS/A%20Multi-Armed%20Bandit%20Framework%20for%20Recommendations%20at%20Netflix.pdf) Netflix